# Проект DLS 1 семестр осень 2020 image generation.

Мне удалось сделать только 1 пункт &mdash; повторить существующее решение
с существующей архитектурой модели, но моей реализацией.
Придумать другую задачу и найти подходящие датасеты мне не удалось.

Из-за отсутствия собственных вычислительных мощностей повторял решение в Google Colab,
после этого портировал в отдельные Python-файлы,
но работоспособность самого тренировочного цикла проверить не на чем.

Скрипт для загрузки датасета: `bin/dataset_download.sh` (запускать из корневой директории проекта).

Скрипт для загрузки всех сохраненных весов модели: `bin/model_download_all.sh`.

Только весов после 300 эпох обучения: `bin/model_download_300.sh`.

Запуск самой сети: `python3 src/train.py`.<br>
Возможные аргументы:
- `-t/--train` &mdash; обучать нейросеть, а не использовать для вывода результатов;
- `-e/--epoch <количество эпох>` &mdash; задать количество эпох (также работает и при загрузке предобученных сетей, но нужно убедиться, что соответствующий слепок существует). По-умолчанию 300;
- `-d/--dataset <датасет>` &mdash; задать имя датасета. По умолчанию `facades`. Поиск файлов будет по пути `src/dataset/<датасет>/(test|train|val)/**.jpg`.

[Этот код в Google Colab](https://colab.research.google.com/drive/1oXobmdumJuvfxPpjZwfr2dyi84Gn0Ueg?usp=sharing)
